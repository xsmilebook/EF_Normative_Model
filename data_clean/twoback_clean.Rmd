---
title: "twoback_clean"
output: html_document
---

```{r}
# Load required packages
library(readxl)
library(writexl)
library(dplyr)
library(stringr)
```

# --- Step 1: QC and Within-Subjects Data Processing ---
```{r}
cat("--- Step 1: Starting Within-Subjects Data Processing for 2-Back Task ---\n")

# --- Part 1.A: Trial-level Data Extraction and Calculation ---

# Define file paths
datapath <- 'D:/datasets/yunfu/raw_data/twoback_data/raw_data'
output_dir <- 'D:/datasets/yunfu/raw_data/twoback_data/cleaned_data'
age_data_path <- 'D:/datasets/yunfu/raw_data/yunfu_agebyID.xlsx'
report_path <- file.path(output_dir, '2back_report.txt')

# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Define the standard column names
new_column_names <- c(
  "task_name", "id", "name", "gender", "age", "game", "school", 
  "grade", "class", "timeall", "hand", "trial", "block", 
  "view_point", "vptime", "materials", "stimulitime", "blank", 
  "blanktime", "pressbutton", "correct", "RT", "ACC", "run"
)

# Get a list of all .xlsx files in the directory
files <- list.files(datapath, pattern = "*.xlsx", full.names = TRUE)

# Initialize a list to store results for each participant
results_list <- list()

# Loop through each data file
for (file_path in files) {
  # Read the Excel sheet, skipping the first 2 rows and assigning custom column names
  data_table <- read_excel(file_path, skip = 2, col_names = FALSE)
  colnames(data_table) <- new_column_names
  
  # Get unique participant IDs from the current file
  unique_ids <- unique(data_table$id)
  
  # Loop through each unique participant
  for (current_id in unique_ids) {
    # Filter data for the current participant
    subjdata_2back <- data_table %>% filter(id == current_id)
    
    # Extract formal trials
    formaldata <- subjdata_2back %>% filter(str_detect(trial, "正式"))
    
    # Select trials from the 3rd to the 58th position
    formaldata_2back <- formaldata[3:min(58, nrow(formaldata)), ]
    
    # Convert RT to numeric and filter trials outside the 200-2000ms range
    formaldata_2back$RT <- as.numeric(formaldata_2back$RT)
    formaldata_RTfiltered <- formaldata_2back %>% 
      filter(RT > 200 & RT < 2001)
    
    # Calculate the percentage of removed trials (based on 56 expected trials: 58-3+1)
    fast_trials <- 56 - nrow(formaldata_RTfiltered)
    deleted_trials_percent <- fast_trials / 56
    
    # --- Calculate Performance Metrics ---
    
    # Overall accuracy
    twoback_acc <- mean(formaldata_RTfiltered$ACC == "正确", na.rm = TRUE)
    
    # Performance on "same" (target) trials (correct response 'F')
    same_trials <- formaldata_RTfiltered %>% filter(correct == 'F')
    same_acc <- mean(same_trials$ACC == "正确", na.rm = TRUE)
    
    # Performance on "different" (non-target) trials (correct response 'J')
    diff_trials <- formaldata_RTfiltered %>% filter(correct == 'J')
    diff_acc <- mean(diff_trials$ACC == "正确", na.rm = TRUE)
    
    # Percentage of removed trials for each condition (based on expected counts)
    deleted_same_trials_percent <- (19 - nrow(same_trials)) / 19
    deleted_diff_trials_percent <- (37 - nrow(diff_trials)) / 37
    
    # Mean RT for correct trials only
    correct_trials_filtered <- formaldata_RTfiltered %>% filter(ACC == "正确")
    mean_RT <- mean(correct_trials_filtered$RT, na.rm = TRUE)
    same_rt <- mean(correct_trials_filtered$RT[correct_trials_filtered$correct == 'F'], na.rm = TRUE)
    diff_rt <- mean(correct_trials_filtered$RT[correct_trials_filtered$correct == 'J'], na.rm = TRUE)
    
    # Performance on the last 6 test trials
    test_trials <- subjdata_2back %>% filter(str_detect(trial, '测试'))
    last6_test_trials <- tail(test_trials, 6)
    test_acc <- mean(last6_test_trials$ACC == "正确", na.rm = TRUE)
    test_RT <- mean(as.numeric(last6_test_trials$RT), na.rm = TRUE)
    
    # Extract 'ptime' from test trial name
    ptime <- NA
    for (test_trial_str in last6_test_trials$trial) {
      ptime_match <- str_match(test_trial_str, "测试-(\\d)")
      if (!is.na(ptime_match[1, 2])) {
        ptime <- as.numeric(ptime_match[1, 2])
        break
      }
    }
    
    # Extract participant demographic information
    name <- subjdata_2back$name[1]
    gender <- subjdata_2back$gender[1]
    age <- subjdata_2back$age[1]
    school <- subjdata_2back$school[1]
    grade <- subjdata_2back$grade[1]
    hand <- subjdata_2back$hand[1]
    
    # Append the results for this participant to the list
    results_list[[length(results_list) + 1]] <- data.frame(
      ID = current_id, Name = name, Gender = gender, Age = age, School = school, Grade = grade, Hand = hand,
      Twoback_acc = twoback_acc, Mean_RT = mean_RT,
      Same_acc = same_acc, Same_rt = same_rt,
      Diff_acc = diff_acc, Diff_rt = diff_rt,
      Test_acc = test_acc, Test_RT = test_RT, Ptime = ptime,
      Deleted_Trials_Percent = deleted_trials_percent,
      Deleted_Same_Trials_Percent = deleted_same_trials_percent,
      Deleted_Diff_Trials_Percent = deleted_diff_trials_percent
    )
  }
}

# Combine all participant results into a single data frame
ResultTable <- bind_rows(results_list)

# Save the initial processed data
write_xlsx(ResultTable, file.path(output_dir, '2back_clean.xlsx'))
cat(sprintf("Initial data processing complete. Found %d unique participants.\'n", nrow(ResultTable)))


# --- Part 1.B: Participant-level Filtering (Exclusion Criteria) ---

# Read the processed data
data <- read_excel(file.path(output_dir, '2back_clean.xlsx'))

# Remove duplicate participant IDs
initial_count <- nrow(data)
cleanedData <- data %>% distinct(ID, .keep_all = TRUE)
removed_count <- initial_count - nrow(cleanedData)
cat(sprintf("Step 1.1: Removed duplicate IDs.                | Removed: %4d | Remaining: %4d\n", removed_count, nrow(cleanedData)))

# Save the deduplicated data
write_xlsx(cleanedData, file.path(output_dir, '2back_cleaned.xlsx'))

# Merge with age data
table1 <- read_excel(file.path(output_dir, '2back_cleaned.xlsx'))
table2 <- read_excel(age_data_path)
table2_sub <- table2 %>% select(ID, Name, Age_day, Age_month, Age_year)
combinetable <- left_join(table1, table2_sub, by = c("ID", "Name"))

# Save the merged data
write_xlsx(combinetable, file.path(output_dir, '2back_clean_combineage.xlsx'))
cat("Step 1.2: Merged with age data successfully.\n\n")

cat("--- Starting Participant Exclusion Process ---\n")

# Initialize the report file
if (file.exists(report_path)) file.remove(report_path)
file.create(report_path)
write("Data Cleaning Report: 2-Back Task", file = report_path, append = FALSE)
write("-------------------------------------\n", file = report_path, append = TRUE)

# Helper function to report cleaning steps
report_step <- function(data_before, data_after, reason, report_file) {
  removed <- nrow(data_before) - nrow(data_after)
  remaining <- nrow(data_after)
  cat(sprintf("%-50s | Removed: %4d | Remaining: %4d\n", reason, removed, remaining))
  write(sprintf("%s: %d, %d", reason, removed, remaining), file = report_file, append = TRUE)
  return(data_after)
}

# The main data frame for cleaning
current_data <- combinetable

# Apply filtering criteria sequentially
current_data <- report_step(current_data, current_data %>% filter(!is.na(Twoback_acc)), "Removed subjects with Twoback_acc of NA", report_path)
current_data <- report_step(current_data, current_data %>% filter(!is.na(Same_acc)), "Removed subjects with Same_acc of NA", report_path)
current_data <- report_step(current_data, current_data %>% filter(!is.na(Diff_acc)), "Removed subjects with Diff_acc of NA", report_path)


current_data <- report_step(current_data, current_data %>% filter(School != '清华大学西区'), "Removed test subjects (school = '清华大学西区')", report_path)
current_data <- report_step(current_data, current_data %>% filter(!is.na(Age_year) & !is.na(as.numeric(Age))), "Removed subjects with missing age data", report_path)
current_data$Age <- as.numeric(current_data$Age)
current_data <- report_step(current_data, current_data %>% filter(abs(Age_year - Age) <= 1), "Removed subjects with inconsistent age records", report_path)
current_data <- report_step(current_data, current_data %>% filter(Age_year > 11 & Age_year <= 18), "Removed subjects outside of age range (11-18 years)", report_path)
current_data <- report_step(current_data, current_data %>% filter(!is.na(Gender) & Gender != ""), "Removed subjects with missing gender data", report_path)
current_data <- report_step(current_data, current_data %>% filter(Deleted_Trials_Percent <= 0.5), "Removed subjects with < 50% valid trials", report_path)
current_data <- report_step(current_data, current_data %>% filter(Twoback_acc > 0), "Removed subjects with Twoback_acc of 0", report_path)
current_data <- report_step(current_data, current_data %>% filter(Same_acc > 0), "Removed subjects with Same_acc of 0", report_path)
current_data <- report_step(current_data, current_data %>% filter(Diff_acc > 0), "Removed subjects with Diff_acc of 0", report_path)
current_data <- report_step(current_data, current_data %>% filter(!(Same_acc <= 0.2 | Diff_acc <= 0.2)), "Removed subjects who did not understand the rule", report_path)

# Save the final within-subjects cleaned data
write_xlsx(current_data, file.path(output_dir, '2back_within.xlsx'))
cat(sprintf("\nWithin-subjects cleaning complete. Final participant count: %d\n", nrow(current_data)))
```
# --- Step 2: Between-Subjects Cleaning (Outlier Removal) ---

```{r}
cat("\n--- Step 2: Starting Between-Subjects Cleaning (Outlier Removal) for 2-Back Task ---\n")
write("\n--- Between-Subjects Cleaning (2-Back) ---\n", file = report_path, append = TRUE)

data_before_outliers <- read_excel(file.path(output_dir, '2back_within.xlsx'))

# --- [NEW] Defensive Check: Ensure all participants are within the expected age range ---
# This prevents the creation of 'NA' age groups by the cut() function.
initial_rows <- nrow(data_before_outliers)
data_before_outliers <- data_before_outliers %>% 
  filter(!is.na(Age_year) & Age_year >= 11 & Age_year <= 18)
rows_removed <- initial_rows - nrow(data_before_outliers)
if (rows_removed > 0) {
  cat(sprintf("INFO: Removed %d rows with 'Age_year' outside [11, 18] before grouping.\n", rows_removed))
  write(sprintf("INFO: Removed %d rows with 'Age_year' outside [11, 18] before grouping.", rows_removed), file = report_path, append = TRUE)
}

# Create age groups
binEdges <- 11:18
data_before_outliers <- data_before_outliers %>% 
  mutate(ageGroups = cut(Age_year, breaks = binEdges, right = TRUE, include.lowest = TRUE, labels = paste(binEdges[-length(binEdges)], binEdges[-1], sep="-")))

# --- Step 2.1: Identify outliers based on Twoback_acc ---
# This table contains ALL participants, with new columns indicating group stats and outlier status.
outlier_data <- data_before_outliers %>%
  filter(!is.na(ageGroups)) %>% # A safeguard against any remaining NA groups
  group_by(ageGroups) %>%
  mutate(
    mean_acc = mean(Twoback_acc, na.rm = TRUE),
    sd_acc = sd(Twoback_acc, na.rm = TRUE),
    is_outlier = abs(Twoback_acc - mean_acc) > 3 * sd_acc
  ) %>%
  ungroup()

# --- Step 2.2: Generate a summary report ---
# This summary table is used to guide the detailed reporting loop.
outlier_summary <- outlier_data %>%
  group_by(ageGroups) %>%
  summarise(
    mean_for_report = first(mean_acc), # Use the already calculated mean
    sd_for_report = first(sd_acc),     # Use the already calculated sd
    n_outliers = sum(is_outlier, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  filter(n_outliers > 0)

# --- [MODIFIED] Step 2.3: Write a DETAILED report for each outlier ---
cat("\n--- Detailed Twoback_acc Outlier Report ---\n")
for (i in 1:nrow(outlier_summary)) {
  
  # Print Summary Line
  summary_line <- sprintf("Age Group %s: Found %d outlier(s) | Group Mean=%.4f, Group SD=%.4f", 
                        outlier_summary$ageGroups[i], 
                        outlier_summary$n_outliers[i],
                        outlier_summary$mean_for_report[i],
                        outlier_summary$sd_for_report[i])
  
  cat(summary_line, "\n")
  write(summary_line, file = report_path, append = TRUE)
  
  # Find and List Individual Outliers for the Current Group
  current_age_group <- outlier_summary$ageGroups[i]
  individual_outliers <- outlier_data %>%
    filter(ageGroups == current_age_group & is_outlier == TRUE)
  
  write("    Details of removed participants:", file = report_path, append = TRUE)
    
  # Loop through each individual outlier and print their details
  for (j in 1:nrow(individual_outliers)) {
    outlier_detail_line <- sprintf("    -> Removed Participant ID: %s, Twoback_acc: %.4f (Difference from mean: %.2f SDs)",
                                   individual_outliers$ID[j],
                                   individual_outliers$Twoback_acc[j],
                                   abs(individual_outliers$Twoback_acc[j] - individual_outliers$mean_acc[j]) / individual_outliers$sd_acc[j])
    
    cat(outlier_detail_line, "\n")
    write(outlier_detail_line, file = report_path, append = TRUE)
  }
}

# --- Step 2.4: Finalize and save the cleaned data ---
# Remove the outliers from the main dataset
data_after_outliers <- outlier_data %>% filter(!is_outlier)
removed_outlier_count <- sum(outlier_summary$n_outliers, na.rm = TRUE)

# Report total number of outliers removed
total_summary_line <- sprintf("\n%-50s | Removed: %4d | Remaining: %4d", 
                              "Total Twoback_acc outliers (>3 SD from mean)", 
                              removed_outlier_count, 
                              nrow(data_after_outliers))
cat(total_summary_line, "\n")
# Corrected the task name in the report file write
write(gsub("Oneback", "Twoback", total_summary_line), file = report_path, append = TRUE)

# Clean up temporary columns and save the result
final_between_data <- data_after_outliers %>% select(-mean_acc, -sd_acc, -is_outlier, -ageGroups)
write_xlsx(final_between_data, file.path(output_dir, '2back_between.xlsx'))
cat(sprintf("Between-subjects cleaning complete. Final participant count: %d\n", nrow(final_between_data)))
```

# --- Step 3: Calculate Dependent Variables ---
```{r}

cat("\n--- Step 3: Calculating Dependent Variables ---\n")

twobackTable <- read_excel(file.path(output_dir, '2back_between.xlsx'))
twobackTable$Age <- as.numeric(twobackTable$Age)

# Adjust accuracy rates to avoid 0 or 1 for d-prime calculation
epsilon <- 0.5 / 56 # Small constant based on number of trials
twobackTable <- twobackTable %>%
  mutate(
    # Same_acc is the Hit Rate
    Same_acc_adj = pmin(pmax(Same_acc, epsilon), 1 - epsilon),
    # 1 - Diff_acc is the False Alarm Rate
    Diff_acc_adj = pmin(pmax(Diff_acc, epsilon), 1 - epsilon),
    
    # Calculate d-prime
    d_prime = qnorm(Same_acc_adj) - qnorm(1 - Diff_acc_adj),
    
    # Calculate Inverse Efficiency Scores (IES)
    IES_all = Mean_RT / Twoback_acc,
    IES_same = Same_rt / Same_acc,
    IES_diff = Diff_rt / Diff_acc
  ) %>%
  select(-Same_acc_adj, -Diff_acc_adj) # Remove temporary adjusted columns

# Save the final table with all dependent variables
write_xlsx(twobackTable, file.path(output_dir, '2back_dependent.xlsx'))
cat("Dependent variables (d', IES) calculated and saved.\n")
cat("\n--- Data processing complete. ---\n")
```

